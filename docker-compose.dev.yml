version: "3"
services:
  database:
    hostname: database
    image: postgres:alpine
    environment:
      POSTGRES_PASSWORD: postgres
      POSTGRES_USER: postgres
      POSTGRES_DB: Dev-Schema
      PGDATA: /var/libs/postgresql/data
    healthcheck:
      test: [ 'CMD-SHELL', 'pg_is ready -U postgres' ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    ports:
      - "5432:5432"
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "postgres-service", "service": "postgres-service"}]'
      com.datadoghq.tags.env: 'dev'
      com.datadoghq.tags.service: 'postgres-service'
      com.datadoghq.tags.version: "1"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.2.0
    ports:
      - "9200:9200"
    environment:
      - "discovery.type=single-node"
    volumes:
      - ./elasticsearch/data:/usr/share/elasticsearch/data:rw              # Persistence data
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "elasticsearch-service", "service": "elasticsearch-service"}]'
      com.datadoghq.tags.env: 'dev'
      com.datadoghq.tags.service: 'elasticsearch-service'
      com.datadoghq.tags.version: "1"

  logstash:
      image: docker.elastic.co/logstash/logstash:7.2.0
      ports:
        - "25826:25826"
        - "5044:5044"
      volumes:
        - ./Dev-Deployment-Config/logstash:/usr/share/logstash/pipeline:ro                # Pipeline configuration
      restart: on-failure
      depends_on:
        - elasticsearch
      labels:
        com.datadoghq.ad.init_configs: '[{}]'
        com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
        com.datadoghq.ad.logs: '[{"source": "logstash-service", "service": "logstash-service"}]'
        com.datadoghq.tags.env: 'dev'
        com.datadoghq.tags.service: 'logstash-service'
        com.datadoghq.tags.version: "1"

  kibana:
      image: docker.elastic.co/kibana/kibana:7.2.0
      ports:
        - "5601:5601"
      restart: on-failure
      depends_on:
        - elasticsearch
      labels:
        com.datadoghq.ad.init_configs: '[{}]'
        com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
        com.datadoghq.ad.logs: '[{"source": "kibana-service", "service": "kibana-service"}]'
        com.datadoghq.tags.env: 'dev'
        com.datadoghq.tags.service: 'kibana-service'
        com.datadoghq.tags.version: "1"

  filebeat:
      image: docker.elastic.co/beats/filebeat:7.2.0
      entrypoint: "filebeat -e -strict.perms=false"
      volumes:
        - ./Dev-Deployment-Config/filebeat/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml:ro # Configuration file
        - /var/lib/docker/containers:/var/lib/docker/containers:ro           # Docker logs
        - /var/run/docker.sock:/var/run/docker.sock:ro                       # Additional information about containers
        - ./Dev-Deployment-Config/filebeat/data:/usr/share/filebeat/data:rw                        # Persistence data
      user: root                                                             # Allow access to log files and docker.sock
      restart: on-failure
      depends_on:
        - logstash
      labels:
        com.datadoghq.ad.init_configs: '[{}]'
        com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
        com.datadoghq.ad.logs: '[{"source": "filebeat-service", "service": "filebeat-service"}]'
        com.datadoghq.tags.env: 'dev'
        com.datadoghq.tags.service: 'filebeat-service'
        com.datadoghq.tags.version: "1"

  cosmos-service:
        hostname: cosmos-dev
        build:
          context: .
          dockerfile: Dockerfile
        ports:
          - "8443:8443"
        container_name: cosmos-service
        restart: on-failure
        depends_on:
          - database
          - filebeat
        labels:
          collect_logs_with_filebeat: "true"
          decode_log_event_to_json_object: "true"
          com.datadoghq.ad.init_configs: '[{}]'
          com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
          com.datadoghq.ad.logs: '[{"source": "comsos-service", "service": "comsos-service"}]'
          com.datadoghq.tags.env: 'dev'
          com.datadoghq.tags.service: 'cosmos-service'
          com.datadoghq.tags.version: "1"
  datadoghq:
    ports:
      - '80:80'
    volumes:
      - '/var/run/docker.sock:/tmp/docker.sock:ro'
      - '/var/run/docker.sock:/var/run/docker.sock:ro'
      - '/proc/:/host/proc/:ro'
      - '/sys/fs/cgroup/:/host/sys/fs/cgroup:ro'
    restart: always
    logging:
      options:
        max-size: 1g
    container_name: dd-agent
    environment:
      - DD_API_KEY=4a5c0384d63f3d1f9d64acd40a60159e
      - DD_SITE=datadoghq.eu
      - DD_APM_ENABLED=true
      - DD_LOGS_ENABLED=true
      - DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL=true
      - DD_DOGSTATSD_NON_LOCAL_TRAFFIC=true
      - DD_CONTAINER_EXCLUDE=image:gcr.io/datadoghq/agent*
      - DD_CONTAINER_EXCLUDE_METRICS=image:gcr.io/datadoghq/agent*
      - DD_CONTAINER_EXCLUDE_LOGS=image:gcr.io/datadoghq/agent*
    image: 'gcr.io/datadoghq/agent:7'